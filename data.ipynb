{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 ère étape : Créer un fichier csv  avec les coordonnées des landmarks \n",
    "--\n",
    "\n",
    "\n",
    "\n",
    "Les lignes du représentent les coordonnées des points faciaux (landmarks) détectés par le modèle Mediapipe FaceMesh.\n",
    "- landmark_index: Il s'agit de l'indice du point facial (landmark) dans la liste des landmarks détectés. \n",
    "- X: C'est la coordonnée X du landmark. \n",
    "- Y: C'est la coordonnée Y du landmark.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Récupérer les coordonnées d'une vidéo dans un csv (ne pas exécuter cette cellule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3.12' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3.12 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# Ajoutez cette ligne pour spécifier la version de numpy\n",
    "import numpy as np; np_version = np.__version__.split('.')\n",
    "\n",
    "if int(np_version[0]) < 1 or (int(np_version[0]) == 1 and int(np_version[1]) < 20):\n",
    "    raise ImportError(\"Numpy version 1.20.0 or above is required for this version of mediapipe. \"\n",
    "                      \"Please upgrade numpy by running: pip install --upgrade numpy\")\n",
    "\n",
    "\n",
    "\n",
    "# Définition de la fonction eye_aspect_ratio\n",
    "def eye_aspect_ratio(eye):\n",
    "    A = np.linalg.norm(eye[1] - eye[5])\n",
    "    B = np.linalg.norm(eye[2] - eye[4])\n",
    "    C = np.linalg.norm(eye[0] - eye[3])\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    return ear\n",
    "\n",
    "# Définition de la fonction mouth_aspect_ratio\n",
    "def mouth_aspect_ratio(mouth):\n",
    "    A = np.linalg.norm(mouth[1] - mouth[5])\n",
    "    B = np.linalg.norm(mouth[2] - mouth[4])\n",
    "    C = np.linalg.norm(mouth[0] - mouth[3])\n",
    "    mar = (A + B) / (2.0 * C)\n",
    "    return mar\n",
    "\n",
    "# Charger le modèle Mediapipe pour la détection des yeux et des lèvres\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialiser le détecteur de visage et le dessinateur pour les annotations\n",
    "face_mesh = mp_face_mesh.FaceMesh()\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "\n",
    "# Charger la vidéo\n",
    "video_path = 'kss#8-9#F#rldd#28-10.mp4'\n",
    "video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Initialiser des listes pour stocker les données\n",
    "landmarks_all_frames = []\n",
    "\n",
    "# Définir les noms de colonnes\n",
    "left_eye_columns = [f\"left_eye_{i}\" for i in [463, 385, 387, 263, 373, 380]]\n",
    "right_eye_columns = [f\"right_eye_{i}\" for i in [133, 158, 160, 33, 144, 153]]\n",
    "mouth_columns = [f\"mouth_{i}\" for i in [78, 82, 312, 308, 317, 87]]\n",
    "\n",
    "# Créer le fichier CSV et écrire l'en-tête\n",
    "csv_file_path = f\"{video_name}_landmarks.csv\"\n",
    "with open(csv_file_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # Écrire l'en-tête du fichier CSV avec toutes les colonnes\n",
    "    writer.writerow(left_eye_columns + right_eye_columns + mouth_columns)\n",
    "\n",
    "# Lecture de la vidéo\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convertir l'image en niveaux de gris\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Détecter les visages dans l'image\n",
    "    faces = face_mesh.process(frame)\n",
    "\n",
    "    if faces.multi_face_landmarks:\n",
    "        for face_landmarks in faces.multi_face_landmarks:\n",
    "            # Extraire les coordonnées des points des yeux et de la bouche\n",
    "            left_eye_landmarks = [[face_landmarks.landmark[i].x, face_landmarks.landmark[i].y] for i in [463, 385, 387, 263, 373, 380]]\n",
    "            right_eye_landmarks = [[face_landmarks.landmark[i].x, face_landmarks.landmark[i].y] for i in [133, 158, 160, 33, 144, 153]]\n",
    "            mouth_landmarks = [[face_landmarks.landmark[i].x, face_landmarks.landmark[i].y] for i in [78, 82, 312, 308, 317, 87]]\n",
    "\n",
    "            # Ajouter les coordonnées aux listes respectives\n",
    "            landmarks_all_frames.append(left_eye_landmarks + right_eye_landmarks + mouth_landmarks)\n",
    "\n",
    "            # Dessiner les points des yeux sur l'image\n",
    "            mp_drawing.draw_landmarks(frame, face_landmarks, mp_face_mesh.FACEMESH_CONTOURS, landmark_drawing_spec=drawing_spec)\n",
    "\n",
    "    # Afficher la vidéo\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # Arrêter la boucle si la touche 'q' est pressée\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# En dehors de la boucle, écrire les coordonnées dans le fichier CSV\n",
    "with open(csv_file_path, mode='a', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # Écrire les coordonnées dans le fichier CSV\n",
    "    writer.writerows(landmarks_all_frames)\n",
    "    print(f\"Les coordonnées des landmarks ont été sauvegardées dans : {csv_file_path}\")\n",
    "\n",
    "# Libérer la capture vidéo\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Récupérer les coordonnées(x,y) de plusieurs vidéo dans plusieurs csv (à modifier)\n",
    "Il faudrait rajouter la coordonnée z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1702083568.907194       1 gl_context.cc:344] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M1 Pro\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les coordonnées des landmarks ont été sauvegardées dans : kss#1-3#F#rldd#10-0_landmarks.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1702083587.753498       1 gl_context.cc:344] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M1 Pro\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les coordonnées des landmarks ont été sauvegardées dans : kss#8-9#F#rldd#28-10_landmarks.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1702083606.436799       1 gl_context.cc:344] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M1 Pro\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les coordonnées des landmarks ont été sauvegardées dans : kss#1-3#F#rldd#10-0_2_landmarks.csv\n",
      "Terminé\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# Ajoutez cette ligne pour spécifier la version de numpy\n",
    "import numpy as np; np_version = np.__version__.split('.')\n",
    "\n",
    "if int(np_version[0]) < 1 or (int(np_version[0]) == 1 and int(np_version[1]) < 20):\n",
    "    raise ImportError(\"Numpy version 1.20.0 or above is required for this version of mediapipe. \"\n",
    "                      \"Please upgrade numpy by running: pip install --upgrade numpy\")\n",
    "\n",
    "# Charger le modèle Mediapipe pour la détection des yeux et des lèvres\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "def process_video(video_path):\n",
    "    # Initialiser le détecteur de visage et le dessinateur pour les annotations\n",
    "    face_mesh = mp_face_mesh.FaceMesh()\n",
    "    drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "\n",
    "    # Initialiser des listes pour stocker les données\n",
    "    landmarks_all_frames = []\n",
    "\n",
    "    # Définir les noms de colonnes\n",
    "    left_eye_columns = [f\"left_eye_{i}\" for i in [463, 385, 387, 263, 373, 380]]\n",
    "    right_eye_columns = [f\"right_eye_{i}\" for i in [133, 158, 160, 33, 144, 153]]\n",
    "    mouth_columns = [f\"mouth_{i}\" for i in [78, 82, 312, 308, 317, 87]]\n",
    "\n",
    "    # Créer le fichier CSV et écrire l'en-tête\n",
    "    video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "    csv_file_path = f\"{video_name}_landmarks.csv\"\n",
    "    with open(csv_file_path, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        # Écrire l'en-tête du fichier CSV avec toutes les colonnes\n",
    "        writer.writerow(left_eye_columns + right_eye_columns + mouth_columns)\n",
    "\n",
    "    # Charger la vidéo\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Lecture de la vidéo\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convertir l'image en niveaux de gris\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Détecter les visages dans l'image\n",
    "        faces = face_mesh.process(frame)\n",
    "\n",
    "        if faces.multi_face_landmarks:\n",
    "            for face_landmarks in faces.multi_face_landmarks:\n",
    "                # Extraire les coordonnées des points des yeux et de la bouche\n",
    "                left_eye_landmarks = [[face_landmarks.landmark[i].x, face_landmarks.landmark[i].y] for i in [463, 385, 387, 263, 373, 380]]\n",
    "                right_eye_landmarks = [[face_landmarks.landmark[i].x, face_landmarks.landmark[i].y] for i in [133, 158, 160, 33, 144, 153]]\n",
    "                mouth_landmarks = [[face_landmarks.landmark[i].x, face_landmarks.landmark[i].y] for i in [78, 82, 312, 308, 317, 87]]\n",
    "\n",
    "                # Ajouter les coordonnées aux listes respectives\n",
    "                landmarks_all_frames.append(left_eye_landmarks + right_eye_landmarks + mouth_landmarks)\n",
    "\n",
    "                # Dessiner les points des yeux sur l'image\n",
    "                mp_drawing.draw_landmarks(frame, face_landmarks, mp_face_mesh.FACEMESH_CONTOURS, landmark_drawing_spec=drawing_spec)\n",
    "\n",
    "        # Afficher la vidéo\n",
    "        cv2.imshow('Video', frame)\n",
    "\n",
    "        # Arrêter la boucle si la touche 'q' est pressée\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # En dehors de la boucle, écrire les coordonnées dans le fichier CSV\n",
    "    with open(csv_file_path, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        # Écrire les coordonnées dans le fichier CSV\n",
    "        writer.writerows(landmarks_all_frames)\n",
    "        print(f\"Les coordonnées des landmarks ont été sauvegardées dans : {csv_file_path}\")\n",
    "\n",
    "    # Libérer la capture vidéo\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# Liste des vidéos à traiter\n",
    "video_paths = ['kss#1-3#F#rldd#10-0.mp4', 'kss#8-9#F#rldd#28-10.mp4','kss#1-3#F#rldd#10-0_2.mp4']\n",
    "\n",
    "# Traiter chaque vidéo\n",
    "for video_path in video_paths:\n",
    "    process_video(video_path)\n",
    "print(\"Terminé\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 ème étape : Statistiques sur nos données  (ne pas modifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3.12' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3.12 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Chemins des fichiers CSV\n",
    "left_eye_csv_path = \"output_video_opencv_left_eye_landmarks.csv\"\n",
    "right_eye_csv_path = \"output_video_opencv_mouth_landmarks.csv\"\n",
    "mouth_csv_path = \"output_video_opencv_right_eye_landmarks.csv\"\n",
    "\n",
    "# Liste des chemins des fichiers\n",
    "csv_paths = [left_eye_csv_path, right_eye_csv_path, mouth_csv_path]\n",
    "\n",
    "# Dictionnaire pour stocker les résultats\n",
    "results = {}\n",
    "\n",
    "# Parcourir chaque fichier CSV\n",
    "for csv_path in csv_paths:\n",
    "    # Lire le fichier CSV\n",
    "    df = pd.read_csv(csv_path, header=None)\n",
    "\n",
    "    # Récupérer le nom du fichier à partir du chemin\n",
    "    file_name = csv_path.split(\"/\")[-1]\n",
    "\n",
    "    # Initialiser le dictionnaire pour le fichier actuel\n",
    "    results[file_name] = {}\n",
    "\n",
    "    # Récupérer les noms de colonnes à partir de la première ligne\n",
    "    column_names = df.iloc[0]\n",
    "\n",
    "    # Parcourir chaque colonne du dataframe\n",
    "    for col, col_name in zip(df.columns, column_names):\n",
    "        # Ignorer la première ligne (en-tête)\n",
    "        values = df[col][1:].apply(lambda x: np.array(eval(x)) if isinstance(x, str) else x)\n",
    "\n",
    "        # Vérifier si chaque valeur est une liste avant d'accéder à ses éléments\n",
    "        x_values = values.apply(lambda x: x[0] if isinstance(x, (list, np.ndarray)) else x)\n",
    "        y_values = values.apply(lambda x: x[1] if isinstance(x, (list, np.ndarray)) else x)\n",
    "\n",
    "        # Stocker les résultats pour la colonne actuelle avec le nom de l'en-tête\n",
    "        results[file_name][col_name] = {\n",
    "            \"min_x\": x_values.min(),\n",
    "            \"max_x\": x_values.max(),\n",
    "            \"mean_x\": x_values.mean(),\n",
    "            \"min_y\": y_values.min(),\n",
    "            \"max_y\": y_values.max(),\n",
    "            \"mean_y\": y_values.mean(),\n",
    "        }\n",
    "\n",
    "# Afficher les résultats\n",
    "for file_name, values in results.items():\n",
    "    print(f\"Résultats pour le fichier {file_name}:\")\n",
    "    for col_name, stats in values.items():\n",
    "        print(f\"{col_name}:\")\n",
    "        print(f\"  Min X: {stats['min_x']}\")\n",
    "        print(f\"  Max X: {stats['max_x']}\")\n",
    "        print(f\"  Moyenne X: {stats['mean_x']}\")\n",
    "        print(f\"  Min Y: {stats['min_y']}\")\n",
    "        print(f\"  Max Y: {stats['max_y']}\")\n",
    "        print(f\"  Moyenne Y: {stats['mean_y']}\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 ème étape : Créer un data frame avec les valeurs de  EAR et MAR (à modifier)\n",
    "--\n",
    "\n",
    "A partir du csv créee pour les vidéos ['kss#1-3#F#rldd#10-0_landmarks.csv', 'kss#8-9#F#rldd#29-10_landmarks.csv', 'kss#8-9#F#rldd#28-10_landmarks.csv'], calculer pour chaque frame EARdroit, EARgauche, EARmoyen et Mar et les mettre dans un dataframe final.  Dans le dataframe final, on veut que chaque ligne représente 1 vidéo et dans les colonnes on a : \n",
    "voici ce qu'on met dans les colonnes [nomdelavidéo (c'est-à-dire par exemple 'kss#1-3#F#rldd#10-0') , EARgauche_0 (pour la frame 0 ), …,EARgauche_875 (pour la frame 875 ),EARdroit_0 (pour la frame 0 ), …,EARdroit_875 (pour la frame 875 ),EARmoyen0 (pour la frame 0 ), …,EARmoyen_875 (pour la frame 875 ),MAR_0 (pour la frame 0 ), …,MAR_875 (pour la frame 875 )] . Si j'ai 3 vidéos , j'aurais donc un dataframe avec 4 lignes (1 ligne pour les entête et chaque ligne suivante représente 1 vidéo)  et 4*875=4375 colonnes car on a 875 frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traitement en cours pour :  kss#1-3#F#rldd#10-0\n",
      "Traitement en cours pour :  kss#8-9#F#rldd#28-10\n",
      "Traitement en cours pour :  kss#1-3#F#rldd#10-0_2\n",
      "                                   Nom_video EAR_left_0 EAR_left_1 EAR_left_2   \n",
      "kss#1-3#F#rldd#10-0      kss#1-3#F#rldd#10-0   0.118014   0.129428   0.134889  \\\n",
      "kss#8-9#F#rldd#28-10    kss#8-9#F#rldd#28-10   0.121962    0.15786   0.142293   \n",
      "kss#1-3#F#rldd#10-0_2  kss#1-3#F#rldd#10-0_2   0.118014   0.129428   0.134889   \n",
      "\n",
      "                      EAR_left_3 EAR_left_4 EAR_left_5 EAR_left_6 EAR_left_7   \n",
      "kss#1-3#F#rldd#10-0     0.130209   0.129128   0.128823   0.130211   0.129761  \\\n",
      "kss#8-9#F#rldd#28-10    0.150228   0.155248   0.151252   0.154831   0.152732   \n",
      "kss#1-3#F#rldd#10-0_2   0.130209   0.129128   0.128823   0.130211   0.129761   \n",
      "\n",
      "                      EAR_left_8  ... MAR_866 MAR_867 MAR_868 MAR_869 MAR_870   \n",
      "kss#1-3#F#rldd#10-0     0.130481  ...     NaN     NaN     NaN     NaN     NaN  \\\n",
      "kss#8-9#F#rldd#28-10    0.148958  ...     NaN     NaN     NaN     NaN     NaN   \n",
      "kss#1-3#F#rldd#10-0_2   0.130481  ...     NaN     NaN     NaN     NaN     NaN   \n",
      "\n",
      "                      MAR_871 MAR_872 MAR_873 MAR_874 MAR_875  \n",
      "kss#1-3#F#rldd#10-0       NaN     NaN     NaN     NaN     NaN  \n",
      "kss#8-9#F#rldd#28-10      NaN     NaN     NaN     NaN     NaN  \n",
      "kss#1-3#F#rldd#10-0_2     NaN     NaN     NaN     NaN     NaN  \n",
      "\n",
      "[3 rows x 3505 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Fonctions EAR et MAR\n",
    "def eye_aspect_ratio(eye):\n",
    "    A = np.linalg.norm(np.array(eval(eye[1])) - np.array(eval(eye[5])))\n",
    "    B = np.linalg.norm(np.array(eval(eye[2])) - np.array(eval(eye[4])))\n",
    "    C = np.linalg.norm(np.array(eval(eye[0])) - np.array(eval(eye[3])))\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    return ear\n",
    "\n",
    "def EAR_mean(EAR1, EAR2):\n",
    "    return (EAR1 + EAR2) / 2\n",
    "\n",
    "def mouth_aspect_ratio(mouth):\n",
    "    A = np.linalg.norm(np.array(eval(mouth[1])) - np.array(eval(mouth[5])))\n",
    "    B = np.linalg.norm(np.array(eval(mouth[2])) - np.array(eval(mouth[4])))\n",
    "    C = np.linalg.norm(np.array(eval(mouth[0])) - np.array(eval(mouth[3])))\n",
    "    mar = (A + B) / (2.0 * C)\n",
    "    return mar\n",
    "\n",
    "# Charger les données à partir des fichiers CSV\n",
    "# Liste des vidéos à traiter\n",
    "video_names = ['kss#1-3#F#rldd#10-0', 'kss#8-9#F#rldd#28-10', 'kss#1-3#F#rldd#10-0_2']\n",
    "\n",
    "video_paths = [name + '.mp4' for name in video_names]\n",
    "\n",
    "# Créer une liste video_files avec les noms de fichiers modifiés\n",
    "video_files = [name + '_landmarks.csv' for name in video_names]\n",
    "\n",
    "signes = [\"EAR_left\",\"EAR_right\", \"EAR_mean\",\"MAR\"]\n",
    "\n",
    "# Initialiser l'entête du data_frame\n",
    "columns = ['Nom_video']\n",
    "for video_file in video_files:\n",
    "    # Charger le CSV\n",
    "    df = pd.read_csv(video_file)\n",
    "    taille_premiere_colonne = len(df.iloc[:, 0])\n",
    "\n",
    "for signe in signes:\n",
    "    for frame in range(taille_premiere_colonne):  # Supposant 876 frames par vidéo\n",
    "        columns.append(f'{signe}_{frame}')\n",
    "\n",
    "# Créer le DataFrame final\n",
    "df_final = pd.DataFrame(columns=columns)\n",
    "\n",
    "df_final.to_csv('resultat_final.csv', index=False)\n",
    "\n",
    "# Parcourir chaque fichier vidéo\n",
    "for video_name in video_names:\n",
    "    print(\"Traitement en cours pour : \", video_name)\n",
    "\n",
    "    # Charger le CSV\n",
    "    df = pd.read_csv(video_name + '_landmarks.csv')\n",
    "\n",
    "    # Récupérer le nom de la vidéo à partir du nom du fichier\n",
    "    df_final.at[video_name, 'Nom_video'] = video_name\n",
    "\n",
    "    # Calculer l'EAR pour chaque œil et ajouter les valeurs à df_final\n",
    "    for frame in range(len(df)):\n",
    "        eye_coordinates = df.loc[frame, ['left_eye_463', 'left_eye_385', 'left_eye_387', 'left_eye_263', 'left_eye_373', 'left_eye_380']]\n",
    "        EAR = eye_aspect_ratio(eye_coordinates)\n",
    "\n",
    "        # Ajouter la valeur EAR à la colonne correspondante dans df_final\n",
    "        column_name = f'EAR_left_{frame}'\n",
    "        df_final.at[video_name, column_name] = EAR\n",
    "\n",
    "\n",
    "print(df_final)\n",
    "\n",
    "# Transformer df_final en csv\n",
    "df_final.to_csv('resultat_final.csv', index=False)\n",
    "\n",
    "# Enregistrez le DataFrame final dans un fichier CSV\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
